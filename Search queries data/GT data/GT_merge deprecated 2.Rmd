Import and merge GT data
Tuesday, February 25 2025

This file will import the manually downloaded GT data, merge into a monthly series, and export (for later additions of covariates).

- - - - - - - - - - - - - - - - - - - -

Which variable do you want to test? 
```{r}
var_name <- 'total visitors, all types' 

#Options
# 'total visitors, all types' *
# 'business visitors' * 
# 'private travelers' *
# 'transit travelers' * 
# 'permanent move' (low variation)
# 'vehicle maintenance personnel'
```

What criterion do you want to use?
```{r}
selected_k = 2

#Options 
# AIC: 2 
# <2 for relaxed AIC (?)
```

Which threshold for VIF?
```{r}
vif_threshold = 10

#5 is a good level to prevent multicollinearity from interfering
#10 is most common and supposed to be less rigorous
#both look very different
#6.5 is in the middle but looks a lot like 10
```





```{r}
library(forecast)
library(tseries)
library(readr)
library(stringr)
library(lubridate)
library(dplyr)
library(zoo)
library(readxl)
library(tidyverse)
library(glmnet)
library(sp)
```


```{r}
# Define the directory containing the GT data
data_dir <- "/Users/michelle/Documents/thesis/Search queries data/GT data/raw keyword data"

# List all CSV files in the directory
files <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

# Initialize an empty list to store the dataframes
data_list <- list()

# Loop through each file, read the data, and process it
for (file in files) {
  # Extract the keyword (filename without extension) for the column name
  keyword <- basename(file) %>% str_remove(".csv")
  
  # Read the CSV file
  temp_df <- read_csv(file, skip = 1)  # Assuming the first row is not part of the actual data
  
  # Rename the columns: 'Month' and 'Frequency'
  colnames(temp_df) <- c("Month", keyword)
  
  # Clean up the 'Month' column to ensure it's in a proper date format
  temp_df$Month <- ym(temp_df$Month)
  
  # Group by 'Month' and summarize by taking the sum of frequencies (or use mean if needed)
  temp_df <- temp_df %>%
    group_by(Month) %>%
    summarise(across(starts_with(keyword), mean, na.rm = TRUE))
  
  # Add this dataframe to the list
  data_list[[keyword]] <- temp_df
}

# Merge all the dataframes in the list by the 'Month' column
merged_df <- Reduce(function(x, y) full_join(x, y, by = "Month"), data_list)

# View the merged dataframe
head(merged_df)

merged_df_copy <- merged_df
```

```{r}
library(dplyr)
library(lubridate)

# Convert monthly data to quarterly by summing values within each quarter
quarterly_df <- merged_df_copy %>%
  mutate(Quarter = floor_date(Month, "quarter")) %>%  # Assign each month to its quarter
  group_by(Quarter) %>%
  summarise(across(where(is.numeric), sum, na.rm = TRUE)) %>%  # Sum all numeric columns
  ungroup()
```

```{r}
# Loop through every column except 'Quarter'
quarterly_df <- quarterly_df %>%
  mutate(
    # Create log_* columns for each numeric variable
    across(.cols = -Quarter, .fns = ~ if_else(. > -1, log1p(.), NA_real_), .names = "log_{.col}")
  )
```

```{r}
# Generate ratio_* and diff_* variables
quarterly_df <- quarterly_df %>%
  mutate(
    work_ratio = jumush / rabota,
    #yunistream_ratio = yunistream_kyrgyzstan / yunistream, (this is 0/0 for many)
    findwork_ratio = jumush_izdeim / poisk_raboti,
    salary_ratio = ailyk / zarplata,
    #zolotaya_korona_ratio = zolotaya_korona_kyrgyzstan / zolotaya_korona,  (this is 0/0 for many)
    
    # Generate diff_* variables with reversed order (Russia - Kyrgyzstan)
    work_diff = rabota - jumush,
    yunistream_diff = yunistream - yunistream_kyrgyzstan,
    findwork_diff = poisk_raboti - jumush_izdeim,
    salary_diff = zarplata - ailyk,
    zolotaya_korona_diff = zolotaya_korona - zolotaya_korona_kyrgyzstan
  )
```

```{r}
# Loop through every column except 'Quarter'
quarterly_df <- quarterly_df %>%
  mutate(
    
    # Create lag_* columns for each numeric variable (including logs)
    across(.cols = -Quarter, .fns = lag, .names = "lag_{.col}")
  )
```

```{r}
quarterly_df <- quarterly_df %>%
  filter(Quarter >= ymd("2010-01-01"),
         Quarter < ymd("2025-01-01")) 
```

Prep to merge the target variable into the dataframe
```{r}
inflows_quarterly <- read_excel("~/Documents/thesis/Macrodata/Cleaned macrodata (intermediate)/QUARTERLY_MIGRANT_FLOWS_CLEANED.xls")

# Pivot the data to long format
inflows_quarterly <- inflows_quarterly %>%
  pivot_longer(
    cols = -`Type of Visitation`,  # Keep the "Type of Visitation" column as is
    names_to = "Quarter",          # New column for quarter labels
    values_to = "Value"            # New column for values
  ) %>%
  arrange(`Type of Visitation`, Quarter)

# Pivot to wide format to make each visitation type a separate column
inflows_quarterly <- inflows_quarterly %>%
  pivot_wider(
    names_from = `Type of Visitation`,  # Use visitation type as column names
    values_from = Value                 # Fill with corresponding values
  ) %>%
  arrange(Quarter)

# Convert Quarter to a date-like format (yearqtr from zoo)
inflows_quarterly <- inflows_quarterly %>%
  mutate(Quarter = as.yearqtr(Quarter, format = "%Y Q%q"))

#Take only the total variable
inflows_quarterly <- inflows_quarterly %>%
  mutate(Kyrgyz_visitors = inflows_quarterly[[var_name]]) %>%
  dplyr::select(Quarter, Kyrgyz_visitors)
```


Drop the levels to prevent heterosked. 
```{r}
cols_to_drop <- c(
  "ailyk", "aviabilet_bishkek", "bilet_bishkek", "jumush_izdeim", "jumush", 
  "perevodi_deneg", "poisk_raboti", "rabota", "vakansii", "yunistream", 
  "zarplata", "zolotaya_korona",
  "lag_ailyk", "lag_aviabilet_bishkek", "lag_bilet_bishkek", "lag_jumush_izdeim", "lag_jumush", 
  "lag_perevodi_deneg", "lag_poisk_raboti", "lag_rabota", "lag_vakansii", "lag_yunistream", 
  "lag_zarplata", "lag_zolotaya_korona"
)

quarterly_df <- quarterly_df[, !(names(quarterly_df) %in% cols_to_drop)]
```


Extending the time series

1. Prepare the data (Ensure it's in quarterly format).
2. Create seasonal dummies (if seasonality is present).
3. Use stepwise AIC selection to choose the best covariates.
4. Fit an ARIMA model incorporating the selected covariates.
5. Generate forecasts to extend the time series.



```{r}
# Ensure data is quarterly
quarterly_df <- quarterly_df %>%
  mutate(Quarter = as.yearqtr(Quarter)) %>%
  arrange(Quarter)

quarterly_df_copy <- quarterly_df
```

```{r}
# Merge datasets on "Quarter"
quarterly_df <- inflows_quarterly %>%
  left_join(quarterly_df, by = "Quarter")
```

Shorten the covariate series for estimation of the model
```{r}
quarterly_df_2010_16 <- quarterly_df %>%
  filter(!is.na(Kyrgyz_visitors)) %>%
  filter(complete.cases(.))  # Remove rows with NA in any of the predictors
```

```{r}
# Convert time series to ts object
y_full <- quarterly_df_2010_16$Kyrgyz_visitors
y_choppedlags <- y_full[-c(1:4)]
```

Make seasonal dummies for later
```{r}
# Create seasonal dummies based on the 'Quarter' column
seasonal_dummies <- model.matrix(~ as.factor(quarter(Quarter)) - 1, data = quarterly_df_2010_16)

# Convert the resulting matrix to a data frame
seasonal_dummies_df <- as.data.frame(seasonal_dummies)

# Set appropriate column names
colnames(seasonal_dummies_df) <- paste0("Q", 1:ncol(seasonal_dummies_df))
```


Prep quarterly_df_2010_16
```{r}
quarterly_df_2010_16 <- quarterly_df_2010_16 %>%
  dplyr::select(-Quarter, -Kyrgyz_visitors) %>%
  dplyr::mutate_all(as.numeric)
```

1. Remove covariates based on not being correlated enough with y (SIS)
```{r}
# Compute absolute correlations between each predictor and y_full
cor_values <- apply(quarterly_df_2010_16, 2, function(x) cor(x, y_full, use = "complete.obs"))

# Rank features by absolute correlation
sorted_features <- names(sort(abs(cor_values), decreasing = TRUE))

# Select the top 15-20 predictors (max to estimate VIF and model stably)
k <- min(20, length(sorted_features))  # Adjust k as needed
selected_features <- sorted_features[1:k]

# Subset the dataset to these features
quarterly_df_selected <- quarterly_df_2010_16[, selected_features]
```

2. Prune collinear covariates
```{r}
library(car)

drop_high_vif <- function(df, response, threshold = vif_threshold) {
  model <- lm(response ~ ., data = df)
  vif_vals <- vif(model)
  while (max(vif_vals) > threshold) {
    df <- df[, -which.max(vif_vals)]  # Drop the most collinear predictor
    model <- lm(response ~ ., data = df)  # Refit the model
    vif_vals <- vif(model)
  }
  return(df)
}

quarterly_df_selected <- drop_high_vif(quarterly_df_selected, y_full)
```

Now we can add in the AR and seasonal dummies!
```{r}
# Create AR(4) features for Kyrgyz_visitors
AR_columns <- inflows_quarterly %>%
  mutate(
    # Create lagged features for AR(4)
    AR1 = lag(Kyrgyz_visitors, 1),
    AR2 = lag(Kyrgyz_visitors, 2),
    AR3 = lag(Kyrgyz_visitors, 3),
    AR4 = lag(Kyrgyz_visitors, 4)
  ) %>%
  # Drop rows with NA values caused by the lags (the first 4 rows will have NAs for the AR variables)
  filter(!is.na(AR1) & !is.na(AR2) & !is.na(AR3) & !is.na(AR4)) %>%
  dplyr::select(-Quarter, -Kyrgyz_visitors)

#Also chop the first 4 values to match lags
quarterly_df_selected <- quarterly_df_selected[-c(1:4), ]
seasonal_dummies_df_chopped <- seasonal_dummies_df[-c(1:4), , drop = FALSE]

```

```{r}
quarterly_df_selected <- cbind(quarterly_df_selected, seasonal_dummies_df_chopped, AR_columns)

# Select potential covariates
covariate_names <- setdiff(names(quarterly_df_selected), c("Quarter", "Kyrgyz_visitors"))
```

```{r}
# Load necessary packages
library(MASS)
library(sandwich)
library(lmtest)
# Ensure response variable and predictors are in correct format
y_full <- as.numeric(y_choppedlags)  # Ensure y_full is numeric

# Fit initial full model using linear regression
full_model <- lm(y_full ~ ., data = quarterly_df_selected)

# Apply stepwise AICc for model selection
stepwise_model <- stepAIC(full_model, direction = "both", trace = TRUE, k = selected_k)

# Compute robust standard errors using the sandwich estimator
robust_se <- vcovHC(stepwise_model, type = "HC3")

# Compute robust coefficient tests
coeftest(stepwise_model, vcov = robust_se)

# Display summary of the stepwise model
summary(stepwise_model)
```



~ ~ ~

Prep to predict
```{r}
quarterly_df <- quarterly_df_copy

# Create seasonal dummies based on the 'Quarter' column
seasonal_dummies <- model.matrix(~ as.factor(quarter(Quarter)) - 1, data = quarterly_df)

# Convert the resulting matrix to a data frame
seasonal_dummies_df <- as.data.frame(seasonal_dummies)

# Set appropriate column names
colnames(seasonal_dummies_df) <- paste0("Q", 1:ncol(seasonal_dummies_df))


# Set the number of periods for prediction (e.g., forecast for the next 28 periods)
forecast_horizon <- 32

# Extend AR_columns with NA values for the forecast horizon
# Create a tibble of NAs with the same number of columns as AR_columns
NA_rows <- as_tibble(matrix(NA, nrow = forecast_horizon, ncol = ncol(AR_columns)))
early_NA_rows <- as_tibble(matrix(NA, nrow = 4, ncol = ncol(AR_columns)))

# Set the column names to match AR_columns
colnames(NA_rows) <- colnames(AR_columns)
colnames(early_NA_rows) <- colnames(AR_columns)

# Combine the original AR_columns with the NA rows
filled_AR_columns <- bind_rows(early_NA_rows, AR_columns, NA_rows)


quarterly_df <- quarterly_df %>%
  cbind(seasonal_dummies_df, filled_AR_columns)
```



```{r}
# Assuming the stepwise_model is already trained and all necessary variables are available

# Initialize a vector to store forecasted values
predictions <- numeric(forecast_horizon)
lower_bound <- numeric(forecast_horizon)
upper_bound <- numeric(forecast_horizon)

# Initialize the start of the forecasting process
forecast_data <- quarterly_df

# Iterate over the forecast horizon
for (i in 1:forecast_horizon) {
  current_row = 23 + i
  next_row = 23 + i + 1
  
  # Predict the next value based on the current model and the last known data point
  prediction_result <- predict(stepwise_model, newdata = forecast_data[current_row, , drop = FALSE], interval = "confidence")
  
  # Store the prediction
  predictions[i] <- as.numeric(prediction_result[1])
  lower_bound[i] <- as.numeric(prediction_result[2])
  upper_bound[i] <- as.numeric(prediction_result[3])
  
  # Add the new prediction to the dataset to simulate the passage of time
  # Note: Here we need to update the seasonal dummies and AR variables to include the new data point
  forecast_data[next_row, "AR1"] <- as.numeric(predictions[i])
  forecast_data[next_row, "AR2"] <- forecast_data[current_row, "AR1"]
  forecast_data[next_row, "AR3"] <- forecast_data[current_row, "AR2"]
  forecast_data[next_row, "AR4"] <- forecast_data[current_row, "AR3"]
    
}

# Show predictions and the confidence intervals for the forecast horizon
results_df <- data.frame(Predictions = predictions, Lower_Bound = lower_bound, Upper_Bound = upper_bound)

```


```{r}
# Step 4: Prepare the results dataframe
combined_actual <- c(inflows_quarterly$Kyrgyz_visitors, rep(NA, length(predictions)))
combined_predictions <- c(rep(NA, length(inflows_quarterly$Kyrgyz_visitors)), predictions)
combined_lower_bound <- c(rep(NA, length(inflows_quarterly$Kyrgyz_visitors)), lower_bound)
combined_upper_bound <- c(rep(NA, length(inflows_quarterly$Kyrgyz_visitors)), upper_bound)

# Combine y and predictions into a single dataframe for plotting
results_df <- data.frame(
  Quarter = quarterly_df_copy$Quarter,
  Actual = combined_actual,
  Predictions = combined_predictions,
  Lower_Bound = combined_lower_bound,
  Upper_Bound = combined_upper_bound
)

results_df$Date <- as.Date(as.yearqtr(results_df$Quarter) + 0.25)  # Adding 0.25 shifts to the end of each quarter
```

Plot!
```{r}
# Plotting with ggplot
ggplot(results_df, aes(x = Date)) +
  # Actual data line
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  
  # Predictions line (dashed)
  geom_line(aes(y = Predictions, color = "Predictions"), size = 1, linetype = "dashed") +
  
  # Confidence interval ribbon
  geom_ribbon(aes(ymin = Lower_Bound, ymax = Upper_Bound), fill = "grey80", alpha = 0.5) +
  
  # Labels and title
  labs(title = "Actual vs Predicted Kyrgyz Visitors",
       subtitle = paste("Variable: ", var_name),
       x = "Quarter",
       y = "Kyrgyz Visitors") +
  
  # Color scale for the legend
  scale_color_manual(name = "Legend", values = c("Actual" = "blue", "Predictions" = "red")) +
  
  # Minimal theme for aesthetics
  theme_minimal() +
  
  # Vertical line for when the war started (e.g., 2022 Q1)
  geom_vline(xintercept = as.Date("2022-02-24"), linetype = "dashed", color = "black") +
  
  # Annotation for the war start
  annotate("text", x = as.Date("2022-02-24"), y = max(results_df$Actual, na.rm = TRUE) * 0.9,
           label = "War begins", angle = 90, hjust = 2.2, vjust = -0.4, color = "black") +
  
  # Vertical line for when the Crocus attack happened
  geom_vline(xintercept = as.Date("2024-03-22"), linetype = "dashed", color = "black") +
  
  # Annotation
  annotate("text", x = as.Date("2024-03-22"), y = max(results_df$Actual, na.rm = TRUE) * 0.9,
           label = "Crocus Hall Attack", angle = 90, hjust = 1.5, vjust = -0.4, color = "black")

ggsave("/Users/michelle/Documents/thesis/plot_extended_time_series_visitors_with_AR.png", width = 10, height = 6)

write.csv(results_df, "/Users/michelle/Documents/thesis/extended_time_series_with_AR.csv", row.names = FALSE)
```

