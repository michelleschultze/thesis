Import and merge GT data
Tuesday, February 25 2025

This file will import the manually downloaded GT data, merge into a monthly series, and export (for later additions of covariates).

- - - - - - - - - - - - - - - - - - - -

Which variable do you want to test? 
```{r}
var_name <- 'total visitors, all types' 

#Options
# 'total visitors, all types' *
# 'business visitors' * 
# 'private travelers' *
# 'transit travelers' * 
# 'permanent move' (low variation)
# 'vehicle maintenance personnel'
```

What criterion do you want to use?
```{r}
selected_k = 2

#Options 
# AIC: 2 
# <2 for relaxed AIC (?)
```

Which threshold for VIF?
```{r}
vif_threshold = 10

#5 is a good level to prevent multicollinearity from interfering
#10 is most common and supposed to be less rigorous
#both look very different
#6.5 is in the middle but looks a lot like 10
```





```{r}
library(forecast)
library(tseries)
library(readr)
library(stringr)
library(lubridate)
library(dplyr)
library(zoo)
library(readxl)
library(tidyverse)
library(glmnet)
library(sp)
library(lmtest)
library(sandwich)
```


```{r}
# Define the directory containing the GT data
data_dir <- "/Users/michelle/Documents/thesis/Search queries data/GT data/raw keyword data"

# List all CSV files in the directory
files <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

# Initialize an empty list to store the dataframes
data_list <- list()

# Loop through each file, read the data, and process it
for (file in files) {
  # Extract the keyword (filename without extension) for the column name
  keyword <- basename(file) %>% str_remove(".csv")
  
  # Read the CSV file
  temp_df <- read_csv(file, skip = 1)  # Assuming the first row is not part of the actual data
  
  # Rename the columns: 'Month' and 'Frequency'
  colnames(temp_df) <- c("Month", keyword)
  
  # Clean up the 'Month' column to ensure it's in a proper date format
  temp_df$Month <- ym(temp_df$Month)
  
  # Group by 'Month' and summarize by taking the sum of frequencies (or use mean if needed)
  temp_df <- temp_df %>%
    group_by(Month) %>%
    summarise(across(starts_with(keyword), mean, na.rm = TRUE))
  
  # Add this dataframe to the list
  data_list[[keyword]] <- temp_df
}

# Merge all the dataframes in the list by the 'Month' column
merged_df <- Reduce(function(x, y) full_join(x, y, by = "Month"), data_list)

# View the merged dataframe
head(merged_df)

merged_df_copy <- merged_df
```

```{r}
library(dplyr)
library(lubridate)

# Convert monthly data to quarterly by summing values within each quarter
quarterly_df <- merged_df_copy %>%
  mutate(Quarter = floor_date(Month, "quarter")) %>%  # Assign each month to its quarter
  group_by(Quarter) %>%
  summarise(across(where(is.numeric), sum, na.rm = TRUE)) %>%  # Sum all numeric columns
  ungroup()
```

```{r}
# Loop through every column except 'Quarter'
quarterly_df <- quarterly_df %>%
  mutate(
    # Create log_* columns for each numeric variable
    across(.cols = -Quarter, .fns = ~ if_else(. > -1, log1p(.), NA_real_), .names = "log_{.col}")
  )
```

```{r}
# Generate ratio_* and diff_* variables
quarterly_df <- quarterly_df %>%
  mutate(
    work_ratio = jumush / rabota,
    #yunistream_ratio = yunistream_kyrgyzstan / yunistream, (this is 0/0 for many)
    findwork_ratio = jumush_izdeim / poisk_raboti,
    salary_ratio = ailyk / zarplata,
    #zolotaya_korona_ratio = zolotaya_korona_kyrgyzstan / zolotaya_korona,  (this is 0/0 for many)
    
    # Generate diff_* variables with reversed order (Russia - Kyrgyzstan)
    work_diff = rabota - jumush,
    yunistream_diff = yunistream - yunistream_kyrgyzstan,
    findwork_diff = poisk_raboti - jumush_izdeim,
    salary_diff = zarplata - ailyk,
    zolotaya_korona_diff = zolotaya_korona - zolotaya_korona_kyrgyzstan
  )
```

```{r}
# Loop through every column except 'Quarter'
quarterly_df <- quarterly_df %>%
  mutate(
    
    # Create lag_* columns for each numeric variable (including logs)
    across(.cols = -Quarter, .fns = lag, .names = "lag_{.col}")
  )
```

```{r}
quarterly_df <- quarterly_df %>%
  filter(Quarter >= ymd("2010-01-01"),
         Quarter < ymd("2025-01-01")) 
```

Prep to merge the target variable into the dataframe
```{r}
inflows_quarterly <- read_excel("~/Documents/thesis/Macrodata/Cleaned macrodata (intermediate)/QUARTERLY_MIGRANT_FLOWS_CLEANED.xls")

# Pivot the data to long format
inflows_quarterly <- inflows_quarterly %>%
  pivot_longer(
    cols = -`Type of Visitation`,  # Keep the "Type of Visitation" column as is
    names_to = "Quarter",          # New column for quarter labels
    values_to = "Value"            # New column for values
  ) %>%
  arrange(`Type of Visitation`, Quarter)

# Pivot to wide format to make each visitation type a separate column
inflows_quarterly <- inflows_quarterly %>%
  pivot_wider(
    names_from = `Type of Visitation`,  # Use visitation type as column names
    values_from = Value                 # Fill with corresponding values
  ) %>%
  arrange(Quarter)

# Convert Quarter to a date-like format (yearqtr from zoo)
inflows_quarterly <- inflows_quarterly %>%
  mutate(Quarter = as.yearqtr(Quarter, format = "%Y Q%q"))

#Take only the total variable
inflows_quarterly <- inflows_quarterly %>%
  mutate(Kyrgyz_visitors = inflows_quarterly[[var_name]]) %>%
  dplyr::select(Quarter, Kyrgyz_visitors)
```


Drop the levels to prevent heterosked. 
```{r}
cols_to_drop <- c(
  "ailyk", "aviabilet_bishkek", "bilet_bishkek", "jumush_izdeim", "jumush", 
  "perevodi_deneg", "poisk_raboti", "rabota", "vakansii", "yunistream", 
  "zarplata", "zolotaya_korona",
  "lag_ailyk", "lag_aviabilet_bishkek", "lag_bilet_bishkek", "lag_jumush_izdeim", "lag_jumush", 
  "lag_perevodi_deneg", "lag_poisk_raboti", "lag_rabota", "lag_vakansii", "lag_yunistream", 
  "lag_zarplata", "lag_zolotaya_korona"
)

quarterly_df <- quarterly_df[, !(names(quarterly_df) %in% cols_to_drop)]
```


Extending the time series

1. Prepare the data (Ensure it's in quarterly format).
2. Create seasonal dummies (if seasonality is present).
3. Use stepwise AIC selection to choose the best covariates.
4. Fit an ARIMA model incorporating the selected covariates.
5. Generate forecasts to extend the time series.



```{r}
# Ensure data is quarterly
quarterly_df <- quarterly_df %>%
  mutate(Quarter = as.yearqtr(Quarter)) %>%
  arrange(Quarter)

quarterly_df_copy <- quarterly_df
```

```{r}
# Merge datasets on "Quarter"
quarterly_df <- inflows_quarterly %>%
  left_join(quarterly_df, by = "Quarter")
```

Shorten the covariate series for estimation of the model
```{r}
quarterly_df_2010_16 <- quarterly_df %>%
  filter(!is.na(Kyrgyz_visitors)) %>%
  filter(complete.cases(.))  # Remove rows with NA in any of the predictors
```

```{r}
y_full <- quarterly_df_2010_16$Kyrgyz_visitors
```

Prep quarterly_df_2010_16
```{r}
quarterly_df_2010_16 <- quarterly_df_2010_16 %>%
  dplyr::select(-Quarter, -Kyrgyz_visitors) %>%
  dplyr::mutate_all(as.numeric)
```

1. Remove covariates based on not being correlated enough with y (SIS)
```{r}
# Compute absolute correlations between each predictor and y_full
cor_values <- apply(quarterly_df_2010_16, 2, function(x) cor(x, y_full, use = "complete.obs"))

# Rank features by absolute correlation
sorted_features <- names(sort(abs(cor_values), decreasing = TRUE))

# Select the top 11 predictors (max to estimate VIF and model stably)
# 24 effective observations due to lags for AR/MA - 4 dummies/intercept - 4 AR terms - 4 MA terms - 1 for full rank = 11
# But it ends up selecting AR(2) and no MA or seasonals even when we only put in 11, so we can include up to 28-2-2-1=23! (20 for safety)
k <- min(20, length(sorted_features))  # Adjust k as needed
selected_features <- sorted_features[1:k]

# Subset the dataset to these features
quarterly_df_selected <- quarterly_df_2010_16[, selected_features]
```

2. Prune collinear covariates
```{r}
library(car)

drop_high_vif <- function(df, response, threshold = vif_threshold) {
  model <- lm(response ~ ., data = df)
  vif_vals <- vif(model)
  while (max(vif_vals) > threshold) {
    df <- df[, -which.max(vif_vals)]  # Drop the most collinear predictor
    model <- lm(response ~ ., data = df)  # Refit the model
    vif_vals <- vif(model)
  }
  return(df)
}

quarterly_df_selected <- drop_high_vif(quarterly_df_selected, y_full)

#update the full set 
quarterly_df <- quarterly_df_copy %>% 
  dplyr::select(Quarter, names(quarterly_df_selected))
```

```{r}
quarterly_df_selected$Quarter <- quarterly_df_copy[1:28, ]$Quarter
```

```{r}
acf(y_full)
pacf(y_full)
```


```{r}
# Convert covariates to time series
covariates_ts <- ts(quarterly_df_selected[, -which(names(quarterly_df_selected) == "Quarter")], frequency = 4)
covariates_ts_full <- ts(quarterly_df[, -which(names(quarterly_df) == "Quarter")], frequency = 4)
covariates_ts_full <- covariates_ts_full[29:60, ]

# Step 1: Fit ARIMA model with seasonal effects using stepwise AIC
# Note: We specify AR(4) and allow stepwise search for the best combination of AR/MA and seasonal components
arima_model <- auto.arima(y_full, xreg = covariates_ts, seasonal = TRUE, stepwise = FALSE, 
                          approximation = FALSE, max.p = 4, max.q = 4, max.P = 2, max.Q = 2, max.D = 1)

# Summary of the ARIMA model
summary(arima_model)

# Step 2: Retrieve model coefficients and diagnostics
coefficients <- coef(arima_model)
print(coefficients)

# Step 3: Generate the forecast for the future periods (assuming forecast_period is defined)
forecast_period <- 32  # Example for 32 quarters ahead
forecast_vals <- forecast(arima_model, xreg = covariates_ts_full, h = forecast_period)

dev.off()

# Step 4: Plot the forecast
plot(forecast_vals)

dev.off()

# Step 6: Diagnostics (Optional, but helpful to check residuals and model fit)
tsdiag(arima_model)  # Diagnostic plots (ACF, PACF, residuals)
```


```{r}
# Assuming that the date of war begins (Feb 24, 2022) and Crocus Hall attacks (Mar 22, 2024) 
# can be mapped to the corresponding quarters in your time series.
# Let's assume the start of your time series is in 2010, and the time series has quarterly data.

# Convert the date "war begins" and "Crocus Hall attacks" to the corresponding quarter index
war_start_date <- as.Date("2022-02-24")
crocus_attack_date <- as.Date("2024-03-22")

# Get the corresponding index for the dates in the time series (convert to quarters)
start_date <- as.Date("2010-01-01")  # Adjust if your time series starts at a different date

# Calculate the number of quarters between the start date and the event dates
war_quarter_index <- as.integer((difftime(war_start_date, start_date, units = "days") / 365.25) * 4)
crocus_quarter_index <- as.integer((difftime(crocus_attack_date, start_date, units = "days") / 365.25) * 4)

dev.off()

# Step 4: Plot the forecast
plot(forecast_vals)

# Add vertical lines for key events
abline(v = war_quarter_index, col = "red", lwd = 2, lty = 2)  # Red dashed line for "War Begins"
abline(v = crocus_quarter_index, col = "blue", lwd = 2, lty = 2)  # Blue dashed line for "Crocus Hall Attacks"

# Add text annotations for the events
text(war_quarter_index, max(forecast_vals$mean), labels = "War Begins (Feb 2022)", pos = 2, col = "red")
text(crocus_quarter_index, max(forecast_vals$mean) + 0.19 * diff(range(forecast_vals$mean)), 
     labels = "Crocus Hall Attacks (Mar 2024)", pos = 2, col = "blue")
```


